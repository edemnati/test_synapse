{
	"name": "SQL_pool_setup",
	"properties": {
		"content": {
			"query": "\n-- Connect to master\nCREATE LOGIN loader WITH PASSWORD = 'a123STRONGpassword!';\n\n-- Connect to the SQL pool\nCREATE USER loader FOR LOGIN loader;\nGRANT ADMINISTER DATABASE BULK OPERATIONS TO loader;\nGRANT INSERT ON <yourtablename> TO loader;\nGRANT SELECT ON <yourtablename> TO loader;\nGRANT CREATE TABLE TO loader;\nGRANT ALTER ON SCHEMA::dbo TO loader;\n\n/*\nDedicated SQL pool workload management in Azure Synapse consists of three high-level concepts:\n\nWorkload Classification:    Allows workload policies to be applied to requests through assigning resource classes and importance.\nWorkload Importance:        Influences the order in which a request gets access to resources\n                            There are five levels of importance: low, below_normal, normal, above_normal, and high. [Default: normal]\nWorkload Isolation:         Reserves resources for a workload group.\n*/\n\nIF EXISTS (SELECT * FROM sys.workload_management_workload_groups where name = 'DataLoads')\nBEGIN\n    DROP WORKLOAD GROUP CEODemo\nEND\nCreate WORKLOAD GROUP DataLoads WITH  \n    (MIN_PERCENTAGE_RESOURCE = 26 -- integer value\n        ,REQUEST_MIN_RESOURCE_GRANT_PERCENT = 3 -- factor of 26 (guaranteed more than 8 concurrencies)\n    ,CAP_PERCENTAGE_RESOURCE = 100\n    )\n\n--Note: [Max Concurrency] = [CAP_PERCENTAGE_RESOURCE] / [REQUEST_MIN_RESOURCE_GRANT_PERCENT]\n\nIF EXISTS (SELECT * FROM sys.workload_management_workload_classifiers WHERE name = 'wgcELTLogin')\nBEGIN\n    DROP WORKLOAD CLASSIFIER  [wgcELTLogin];\nEND\nCREATE WORKLOAD CLASSIFIER [wgcELTLogin]\nWITH (\n        WORKLOAD_GROUP = 'DataLoads'\n    ,MEMBERNAME = 'loader'\n\n\n\n--Ingestion with the COPY activity\nTRUNCATE TABLE wwi_staging.SaleHeap;\nGO\n\n-- Replace YOURACCOUNT with the workspace default storage account name.\nCOPY INTO wwi_staging.SaleHeap\nFROM 'https://YOURACCOUNT.dfs.core.windows.net/wwi-02/sale-small%2FYear%3D2019'\nWITH (\n    FILE_TYPE = 'PARQUET',\n    COMPRESSION = 'SNAPPY'\n)\nGO    \n\nSELECT COUNT(1) FROM wwi_staging.SaleHeap(nolock)\n\n--Other example 1\n--Note when specifying the column list, input field numbers start from 1\nCOPY INTO test_1 (Col_one default 'myStringDefault' 1, Col_two default 1 3)\nFROM 'https://myaccount.blob.core.windows.net/myblobcontainer/folder1/'\nWITH (\n    FILE_TYPE = 'CSV',\n    CREDENTIAL=(IDENTITY= 'Storage Account Key', SECRET='<Your_Account_Key>'),\n\t--CREDENTIAL should look something like this:\n    --CREDENTIAL=(IDENTITY= 'Storage Account Key', \n    --              SECRET='x6RWv4It5F2msnjelv3H4DA80n0PQW0daPdw43jM0nyetx4c6CpDkdj3986DX5AHFMIf/YN4y6kkCnU8lb+Wx0Pj+6MDw=='),\n    FIELDQUOTE = '\"',\n    FIELDTERMINATOR=',',\n    ROWTERMINATOR='0x0A',\n    ENCODING = 'UTF8',\n    FIRSTROW = 2\n)\n\n--Other example 2\n\nCOPY INTO test_1\nFROM 'https://myaccount.blob.core.windows.net/myblobcontainer/folder1/'\nWITH (\n    FILE_TYPE = 'CSV',\n    CREDENTIAL=(IDENTITY= 'Shared Access Signature', SECRET='<Your_SAS_Token>'),\n\t--CREDENTIAL should look something like this:\n    --CREDENTIAL=(IDENTITY= 'Shared Access Signature',  \n    --              SECRET='?sv=2018-03-28&ss=bfqt&srt=sco&sp=rl&st=2016-10-17T20%3A14%3A55Z&se=2021-10-18T20%3A19%3A00Z&sig=IEoOdmeYnE9%2FKiJDSHFSYsz4AkNa%2F%2BTx61FuQ%2FfKHefqoBE%3D'),\n    FIELDQUOTE = '\"',\n    FIELDTERMINATOR=';',\n    ROWTERMINATOR='0X0A',\n    ENCODING = 'UTF8',\n    DATEFORMAT = 'ymd',\n\tMAXERRORS = 10,\n\tERRORFILE = '/errorsfolder',--path starting from the storage container\n\tIDENTITY_INSERT = 'ON'\n)\n\n-------------------------------------------------------------------------------\n--Check query performance\n--Check requests\nselect * from sys.dm_exec_requests; --serverless sql pool\nselect * from sys.dm_pdw_exec_request;--dedicated sql pool\n\n--Test query\nSELECT TOP 1000 * FROM\n(\n    SELECT\n        S.CustomerId\n        ,SUM(S.TotalAmount) as TotalAmount\n    FROM\n        [wwi_perf].[Sale_Heap] S\n    GROUP BY\n        S.CustomerId\n) T\nOPTION (LABEL = 'Lab03: Heap')\n\n--Check execution using label\nSELECT  *\nFROM    sys.dm_pdw_exec_requests\nWHERE   [label] = 'Lab03: Heap';\n\n--Checke Table structure\nCREATE TABLE [wwi_perf].[Sale_Heap]\n( \n  [TransactionId] [uniqueidentifier]  NOT NULL,\n  [CustomerId] [int]  NOT NULL,\n  [ProductId] [smallint]  NOT NULL,\n  [Quantity] [tinyint]  NOT NULL,\n  [Price] [decimal](9,2)  NOT NULL,\n  [TotalAmount] [decimal](9,2)  NOT NULL,\n  [TransactionDateId] [int]  NOT NULL,\n  [ProfitAmount] [decimal](9,2)  NOT NULL,\n  [Hour] [tinyint]  NOT NULL,\n  [Minute] [tinyint]  NOT NULL,\n  [StoreId] [smallint]  NOT NULL\n)\nWITH\n(\n  DISTRIBUTION = ROUND_ROBIN,\n  HEAP\n)\n\n/*\nClustered columnstore index (CCI) Optimization\nUsing a view like the one listed below can help identify the average rows per row group and identify any suboptimal CCIs. \nThe last column in this provided DDL can be used to rebuild those suboptimal indexes.\n*/\nCREATE VIEW dbo.vColumnstoreDensity\nAS\nSELECT\n        GETDATE()                                                               AS [execution_date]\n,       DB_Name()                                                               AS [database_name]\n,       s.name                                                                  AS [schema_name]\n,       t.name                                                                  AS [table_name]\n,    COUNT(DISTINCT rg.[partition_number])                    AS [table_partition_count]\n,       SUM(rg.[total_rows])                                                    AS [row_count_total]\n,       SUM(rg.[total_rows])/COUNT(DISTINCT rg.[distribution_id])               AS [row_count_per_distribution_MAX]\n,    CEILING    ((SUM(rg.[total_rows])*1.0/COUNT(DISTINCT rg.[distribution_id]))/1048576) AS [rowgroup_per_distribution_MAX]\n,       SUM(CASE WHEN rg.[State] = 0 THEN 1                   ELSE 0    END)    AS [INVISIBLE_rowgroup_count]\n,       SUM(CASE WHEN rg.[State] = 0 THEN rg.[total_rows]     ELSE 0    END)    AS [INVISIBLE_rowgroup_rows]\n,       MIN(CASE WHEN rg.[State] = 0 THEN rg.[total_rows]     ELSE NULL END)    AS [INVISIBLE_rowgroup_rows_MIN]\n,       MAX(CASE WHEN rg.[State] = 0 THEN rg.[total_rows]     ELSE NULL END)    AS [INVISIBLE_rowgroup_rows_MAX]\n,       AVG(CASE WHEN rg.[State] = 0 THEN rg.[total_rows]     ELSE NULL END)    AS [INVISIBLE_rowgroup_rows_AVG]\n,       SUM(CASE WHEN rg.[State] = 1 THEN 1                   ELSE 0    END)    AS [OPEN_rowgroup_count]\n,       SUM(CASE WHEN rg.[State] = 1 THEN rg.[total_rows]     ELSE 0    END)    AS [OPEN_rowgroup_rows]\n,       MIN(CASE WHEN rg.[State] = 1 THEN rg.[total_rows]     ELSE NULL END)    AS [OPEN_rowgroup_rows_MIN]\n,       MAX(CASE WHEN rg.[State] = 1 THEN rg.[total_rows]     ELSE NULL END)    AS [OPEN_rowgroup_rows_MAX]\n,       AVG(CASE WHEN rg.[State] = 1 THEN rg.[total_rows]     ELSE NULL END)    AS [OPEN_rowgroup_rows_AVG]\n,       SUM(CASE WHEN rg.[State] = 2 THEN 1                   ELSE 0    END)    AS [CLOSED_rowgroup_count]\n,       SUM(CASE WHEN rg.[State] = 2 THEN rg.[total_rows]     ELSE 0    END)    AS [CLOSED_rowgroup_rows]\n,       MIN(CASE WHEN rg.[State] = 2 THEN rg.[total_rows]     ELSE NULL END)    AS [CLOSED_rowgroup_rows_MIN]\n,       MAX(CASE WHEN rg.[State] = 2 THEN rg.[total_rows]     ELSE NULL END)    AS [CLOSED_rowgroup_rows_MAX]\n,       AVG(CASE WHEN rg.[State] = 2 THEN rg.[total_rows]     ELSE NULL END)    AS [CLOSED_rowgroup_rows_AVG]\n,       SUM(CASE WHEN rg.[State] = 3 THEN 1                   ELSE 0    END)    AS [COMPRESSED_rowgroup_count]\n,       SUM(CASE WHEN rg.[State] = 3 THEN rg.[total_rows]     ELSE 0    END)    AS [COMPRESSED_rowgroup_rows]\n,       SUM(CASE WHEN rg.[State] = 3 THEN rg.[deleted_rows]   ELSE 0    END)    AS [COMPRESSED_rowgroup_rows_DELETED]\n,       MIN(CASE WHEN rg.[State] = 3 THEN rg.[total_rows]     ELSE NULL END)    AS [COMPRESSED_rowgroup_rows_MIN]\n,       MAX(CASE WHEN rg.[State] = 3 THEN rg.[total_rows]     ELSE NULL END)    AS [COMPRESSED_rowgroup_rows_MAX]\n,       AVG(CASE WHEN rg.[State] = 3 THEN rg.[total_rows]     ELSE NULL END)    AS [COMPRESSED_rowgroup_rows_AVG]\n,       'ALTER INDEX ALL ON ' + s.name + '.' + t.NAME + ' REBUILD;'             AS [Rebuild_Index_SQL]\nFROM    sys.[pdw_nodes_column_store_row_groups] rg\nJOIN    sys.[pdw_nodes_tables] nt                   ON  rg.[object_id]          = nt.[object_id]\n                                                    AND rg.[pdw_node_id]        = nt.[pdw_node_id]\n                                                    AND rg.[distribution_id]    = nt.[distribution_id]\nJOIN    sys.[pdw_table_mappings] mp                 ON  nt.[name]               = mp.[physical_name]\nJOIN    sys.[tables] t                              ON  mp.[object_id]          = t.[object_id]\nJOIN    sys.[schemas] s                             ON t.[schema_id]            = s.[schema_id]\nGROUP BY\n        s.[name]\n,       t.[name];\n\n\n/*\nOnce the view is created, run the following query to identify tables with row groups with less than 100K rows. \nOnce these are resolved, increase the threshold to look for additional opportunities for optimal segment quality.\n*/\nSELECT    *\nFROM    [dbo].[vColumnstoreDensity]\nWHERE    COMPRESSED_rowgroup_rows_AVG < 100000\n        OR INVISIBLE_rowgroup_rows_AVG < 100000;\n",
			"metadata": {
				"language": "sql"
			},
			"currentConnection": {
				"databaseName": "master",
				"poolName": "Built-in"
			},
			"resultLimit": 5000
		},
		"type": "SqlQuery"
	}
}