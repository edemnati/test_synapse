{
	"name": "Notebook_wsib_samples",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "myspark",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"runAsWorkspaceSystemIdentity": false,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "165d4d88-3105-4d3c-bac2-2ecfea6d46a9"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/e0d7a68e-191f-4f51-83ce-d93995cd5c09/resourceGroups/my_ml_tests/providers/Microsoft.Synapse/workspaces/ez-az-synapse-test/bigDataPools/myspark",
				"name": "myspark",
				"type": "Spark",
				"endpoint": "https://ez-az-synapse-test.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/myspark",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net",
					"authHeader": null
				},
				"sparkVersion": "3.2",
				"nodeCount": 10,
				"cores": 4,
				"memory": 28,
				"extraHeader": null
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"%%sh\r\n",
					"pip install faker"
				],
				"execution_count": 1
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import random\r\n",
					"import pyspark\r\n",
					"from pyspark.sql import SparkSession, Row\r\n",
					"from faker import Faker\r\n",
					"\r\n",
					"# https://spark.incubator.apache.org/docs/3.0.3/sql-ref-datatypes.html\r\n",
					"from pyspark.sql.types import StructType,StructField, StringType, TimestampType, IntegerType, FloatType, DateType, BooleanType\r\n",
					"\r\n",
					"DLK_LOCATION = \"abfss://ez-filesystem@ezmylake.dfs.core.windows.net\"\r\n",
					"def create_sample_parquet_file(df_schema, df_data, destination_path,mode='append'):\r\n",
					"    df = spark.createDataFrame(df_data,df_schema)\r\n",
					"    (df.write\r\n",
					"       .mode(mode)\r\n",
					"       .parquet(F\"{DLK_LOCATION}/{destination_path}\"))\r\n",
					"\r\n",
					"\r\n",
					""
				],
				"execution_count": 2
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"fake = Faker()\r\n",
					"# create new provider class\r\n",
					"from faker.providers import BaseProvider\r\n",
					"class wsib_provider(BaseProvider):\r\n",
					"    def body_part_detailed(self) -> str:\r\n",
					"        import random\r\n",
					"        list_parts = [\"Face\",\"Eyes\",\"Nose\",\"Ears\",\"Mouth\",\"Tongue\",\"Teeth\",\"Shoulders\",\"Chest\",\r\n",
					"         \"Pectoralis (upper chest)\",\"Ribcage\",\"Lungs\",\"Heart\",\"Upper Abdomen\",\r\n",
					"         \"Abdominal muscles\",\"Stomach\",\"Kidneys\",\"Liver\",\"Arms\",\"Elbow\",\"Left Elbow\",\r\n",
					"         \"Right Elbow\",\"Left Leg\",\"Right Leg\"]\r\n",
					"        return f\"detailed: random.choice(list_parts)\"\r\n",
					"    \r\n",
					"    def body_part_primary(self) -> str:\r\n",
					"        import random\r\n",
					"        list_parts = [\"Face\",\"Eyes\",\"Nose\",\"Ears\",\"Mouth\",\"Tongue\",\"Teeth\",\"Shoulders\",\"Chest\",\r\n",
					"         \"Pectoralis (upper chest)\",\"Ribcage\",\"Lungs\",\"Heart\",\"Upper Abdomen\",\r\n",
					"         \"Abdominal muscles\",\"Stomach\",\"Kidneys\",\"Liver\",\"Arms\",\"Elbow\",\"Left Elbow\",\r\n",
					"         \"Right Elbow\",\"Left Leg\",\"Right Leg\"]\r\n",
					"        return f\"primary: random.choice(list_parts)\"\r\n",
					"\r\n",
					"# then add new provider to faker instance\r\n",
					"fake.add_provider(wsib_provider)\r\n",
					""
				],
				"execution_count": 3
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"mastertypelist_schema = StructType([StructField('ID',StringType(),True)\r\n",
					"                                ,StructField('NAME',StringType(),True)\r\n",
					"                                ,StructField('DESCRIPTION',StringType(),True)\r\n",
					"                                ,StructField('CCTL_NAME',StringType(), True)\r\n",
					"                                ,StructField('audit_batch_ts',TimestampType(), True)])\r\n",
					"mastertypelist_path = \"wsib_raw_sample_data/psaprod.mastertypelist.parquet\"\r\n",
					"mastertypelist_data = [[fake.random_int(min=1,max=1000)\r\n",
					"                        ,fake.name()\r\n",
					"                        ,fake.sentence(nb_words=10)\r\n",
					"                        ,f'CLTName {fake.random_int(min=1,max=1000)}'\r\n",
					"                        ,fake.date_time_this_month()] for i in range(1000)]\r\n",
					"\r\n",
					"create_sample_parquet_file(df_schema=mastertypelist_schema, \r\n",
					"                            df_data=mastertypelist_data, \r\n",
					"                            destination_path=mastertypelist_path\r\n",
					"                            )"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Add a duplicated row\r\n",
					"dup_row=[mastertypelist_data[0]]\r\n",
					"create_sample_parquet_file(df_schema=mastertypelist_schema, \r\n",
					"                            df_data=dup_row, \r\n",
					"                            destination_path=mastertypelist_path\r\n",
					"                            )"
				],
				"execution_count": 8
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"df = spark.read.parquet(F\"{DLK_LOCATION}/{mastertypelist_path}\")\r\n",
					"display(df)\r\n",
					""
				],
				"execution_count": 9
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"cc_claim_schema = StructType([StructField('ID',IntegerType(),True)\r\n",
					"                                ,StructField('PolicyID',IntegerType(),True)\r\n",
					"                                ,StructField('PublicID',IntegerType(),True)\r\n",
					"                                ,StructField('AssignedGroupID',IntegerType(), True)\r\n",
					"                                ,StructField('AssignedUserID',IntegerType(), True)\r\n",
					"                                ,StructField('catastropheid',IntegerType(), True)\r\n",
					"                                ,StructField('ClaimantDenormID',IntegerType(), True)\r\n",
					"                                ,StructField('ClaimNumber',StringType(), True)\r\n",
					"                                ,StructField('ClaimType_WC',StringType(), True)\r\n",
					"                                ,StructField('WSIB_ClaimType',StringType(), True)\r\n",
					"                                ,StructField('Entitlementstate_WC',StringType(), True)\r\n",
					"                                ,StructField('PriorSimilarClaimYesNo_WC',StringType(), True)\r\n",
					"                                ,StructField('PriorSimilarSameArea_WC',StringType(), True)\r\n",
					"                                ,StructField('LossDate',DateType(), True)\r\n",
					"                                ,StructField('WSIB_ClaimRegistrationDate',DateType(), True)\r\n",
					"                                ,StructField('PriorSimilarCond_WC',IntegerType(), True)\r\n",
					"                                ,StructField('WSIB_iseAdjudicatedAllowed',IntegerType(), True)\r\n",
					"                                ,StructField('WSIB_iseAdjudicatedHIA',IntegerType(), True)\r\n",
					"                                ,StructField('updatetime',TimestampType(), True)\r\n",
					"                                ,StructField('audit_batch_ts',TimestampType(), True)])\r\n",
					"cc_claim_path = \"wsib_raw_sample_data/psaprod.cc_claim.parquet\"\r\n",
					"cc_claim_data = [[fake.random_int(min=1,max=1000)\r\n",
					"                    ,fake.random_int(min=1,max=1000)\r\n",
					"                    ,fake.random_int(min=1,max=1000)\r\n",
					"                    ,fake.random_int(min=1,max=1000)\r\n",
					"                    ,fake.random_int(min=1,max=1000)\r\n",
					"                    ,fake.random_int(min=1,max=1000)\r\n",
					"                    ,fake.random_int(min=1,max=1000)\r\n",
					"                    ,fake.bothify(text=f'CLM000{fake.random_int(max=1000)}')\r\n",
					"                    ,fake.random_int(min=10001,max=10007)\r\n",
					"                    ,fake.random_int(min=10001,max=10007)\r\n",
					"                    ,fake.random_int(min=10001,max=10001)\r\n",
					"                    ,fake.random_element(elements=('Yes', 'No'))\r\n",
					"                    ,fake.random_element(elements=('Yes', 'No'))\r\n",
					"                    ,fake.date_this_month()\r\n",
					"                    ,fake.date_this_month()\r\n",
					"                    ,fake.random_int(max=1)\r\n",
					"                    ,fake.random_int(max=1)\r\n",
					"                    ,fake.random_int(max=1)\r\n",
					"                    ,fake.date_time_this_month()\r\n",
					"                    ,fake.date_time_this_month()] for i in range(1000)]\r\n",
					"\r\n",
					"create_sample_parquet_file(df_schema=cc_claim_schema, \r\n",
					"                            df_data=cc_claim_data, \r\n",
					"                            destination_path=cc_claim_path,\r\n",
					"                            #mode='overwrite'\r\n",
					"                            )        "
				],
				"execution_count": 10
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"df = spark.read.parquet(F\"{DLK_LOCATION}/{cc_claim_path}\")\r\n",
					"display(df)\r\n",
					"df.createOrReplaceTempView(\"tbl_cc_claim\")"
				],
				"execution_count": 11
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"%%sql\r\n",
					"\r\n",
					"select *\r\n",
					"from tbl_cc_claim as a\r\n",
					"where a.WSIB_ClaimRegistrationDate is not null\r\n",
					"    and a.ClaimType_WC = 10002\r\n",
					"    and a.WSIB_ClaimType = 10002 \r\n",
					"    and Entitlementstate_WC = 10001"
				],
				"execution_count": 12
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"ccx_WSIB_StatCodeSystem_schema = StructType([StructField('claim',IntegerType(),True)\r\n",
					"                                ,StructField('WSIB_ProjectIDs',IntegerType(),True)])\r\n",
					"ccx_WSIB_StatCodeSystem_path = \"wsib_raw_sample_data/psaprod.ccx_WSIB_StatCodeSystem.parquet\"\r\n",
					"ccx_WSIB_StatCodeSystem_data = [[fake.random_int(min=1,max=1000)\r\n",
					"                        ,fake.random_int(min=1,max=3)] for i in range(1000)]\r\n",
					"\r\n",
					"create_sample_parquet_file(df_schema=ccx_WSIB_StatCodeSystem_schema, \r\n",
					"                            df_data=ccx_WSIB_StatCodeSystem_data, \r\n",
					"                            destination_path=ccx_WSIB_StatCodeSystem_path\r\n",
					"                            )        "
				],
				"execution_count": 13
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"df = spark.read.parquet(F\"{DLK_LOCATION}/{ccx_WSIB_StatCodeSystem_path}\")\r\n",
					"display(df)"
				],
				"execution_count": 14
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"cc_incident_schema = StructType([StructField('ClaimID',IntegerType(),True)\r\n",
					"                                ,StructField('ID',IntegerType(),True)\r\n",
					"                                ,StructField('AccidentCatOptns_WC',IntegerType(),True)\r\n",
					"                                ,StructField('AccidentIllnessCat_WC',IntegerType(),True)\r\n",
					"                                ,StructField('NatureOfAccident_WC',IntegerType(),True)\r\n",
					"                                ,StructField('updatetime',TimestampType(), True)\r\n",
					"                                ,StructField('audit_batch_ts',TimestampType(), True)])\r\n",
					"cc_incident_path = \"wsib_raw_sample_data/psaprod.cc_incident.parquet\"\r\n",
					"cc_incident_data = [[fake.random_int(min=1,max=1000)\r\n",
					"                    ,fake.random_int(min=1,max=1000)\r\n",
					"                    ,fake.random_int(min=10001,max=10044)\r\n",
					"                    ,fake.random_int(min=10001,max=10007)\r\n",
					"                    ,fake.random_int(min=10001,max=10052)\r\n",
					"                    ,fake.date_time_this_month()\r\n",
					"                    ,fake.date_time_this_month()] for i in range(1000)]\r\n",
					"\r\n",
					"create_sample_parquet_file(df_schema=cc_incident_schema, \r\n",
					"                            df_data=cc_incident_data, \r\n",
					"                            destination_path=cc_incident_path\r\n",
					"                            )            "
				],
				"execution_count": 15
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"df = spark.read.parquet(F\"{DLK_LOCATION}/{cc_incident_path}\")\r\n",
					"display(df)"
				],
				"execution_count": 16
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"\r\n",
					"cc_contact_schema = StructType([StructField('ID',IntegerType(),True)\r\n",
					"                                ,StructField('WSIB_MailingAddressID',IntegerType(),True)\r\n",
					"                                ,StructField('WSIB_WCB_ID',IntegerType(),True)\r\n",
					"                                ,StructField('FirstName',StringType(),True)\r\n",
					"                                ,StructField('Gender',StringType(),True)\r\n",
					"                                ,StructField('LastName',StringType(),True)\r\n",
					"                                ,StructField('MiddleName',StringType(),True)\r\n",
					"                                ,StructField('DateOfBirth',DateType(),True)\r\n",
					"                                ,StructField('updatetime',TimestampType(), True)\r\n",
					"                                ,StructField('audit_batch_ts',TimestampType(), True)])\r\n",
					"\r\n",
					"\r\n",
					"cc_contact_path = \"wsib_raw_sample_data/psaprod.cc_contact.parquet\"\r\n",
					"cc_contact_data = [[fake.random_int(min=1,max=1000)\r\n",
					"                    ,fake.random_int(min=1,max=1000)\r\n",
					"                    ,fake.random_int(min=1,max=1000)\r\n",
					"                    ,fake.first_name()\r\n",
					"                    ,fake.random_element(elements=('M', 'F'))\r\n",
					"                    ,fake.last_name()\r\n",
					"                    ,fake.first_name()\r\n",
					"                    ,fake.date_of_birth()\r\n",
					"                    ,fake.date_time_this_month()\r\n",
					"                    ,fake.date_time_this_month()] for i in range(1000)]\r\n",
					"\r\n",
					"create_sample_parquet_file(df_schema=cc_contact_schema, \r\n",
					"                            df_data=cc_contact_data, \r\n",
					"                            destination_path=cc_contact_path\r\n",
					"                            )          "
				],
				"execution_count": 17
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"df = spark.read.parquet(F\"{DLK_LOCATION}/{cc_contact_path}\")\r\n",
					"display(df)"
				],
				"execution_count": 18
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"cc_address_schema = StructType([StructField('ID',IntegerType(),True)\r\n",
					"                                ,StructField('PostalCode',StringType(),True)\r\n",
					"                                ,StructField('updatetime',TimestampType(), True)\r\n",
					"                                ,StructField('audit_batch_ts',TimestampType(), True)])\r\n",
					"cc_address_path = \"wsib_raw_sample_data/psaprod.cc_address.parquet\"\r\n",
					"cc_address_data = [[fake.random_int(max=1000)\r\n",
					"                    ,fake.bothify(text='?%? %?%').upper()\r\n",
					"                    ,fake.date_time_this_month()\r\n",
					"                    ,fake.date_time_this_month()] for i in range(1000)]\r\n",
					"\r\n",
					"create_sample_parquet_file(df_schema=cc_address_schema, \r\n",
					"                            df_data=cc_address_data, \r\n",
					"                            destination_path=cc_address_path\r\n",
					"                            )           "
				],
				"execution_count": 19
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"df = spark.read.parquet(F\"{DLK_LOCATION}/{cc_address_path}\")\r\n",
					"display(df)"
				],
				"execution_count": 20
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"cc_policy_schema = StructType([StructField('ID',IntegerType(),True)\r\n",
					"                                ,StructField('WSIB_Class',IntegerType(),True)\r\n",
					"                                ,StructField('WSIB_NAICS',IntegerType(),True)\r\n",
					"                                ,StructField('WSIB_Schedule_TK',IntegerType(),True)\r\n",
					"                                ,StructField('AccountNumber',StringType(),True)\r\n",
					"                                ,StructField('WSIB_PrimaryCUCode',StringType(),True)\r\n",
					"                                ,StructField('updatetime',TimestampType(), True)\r\n",
					"                                ,StructField('audit_batch_ts',TimestampType(), True)])\r\n",
					"cc_policy_path = \"wsib_raw_sample_data/psaprod.cc_policy.parquet\"\r\n",
					"cc_policy_data = [[fake.random_int(min=1,max=1000)\r\n",
					"                    ,fake.random_int(min=1,max=1000)\r\n",
					"                    ,fake.random_int(min=1,max=1000)\r\n",
					"                    ,fake.random_int(min=10001,max=10007)\r\n",
					"                    ,fake.bban()\r\n",
					"                    ,fake.bothify(text=\"???:???\")\r\n",
					"                    ,fake.date_time_this_month()\r\n",
					"                    ,fake.date_time_this_month()] for i in range(1000)]\r\n",
					"\r\n",
					"create_sample_parquet_file(df_schema=cc_policy_schema, \r\n",
					"                            df_data=cc_policy_data, \r\n",
					"                            destination_path=cc_policy_path\r\n",
					"                            )           "
				],
				"execution_count": 21
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"df = spark.read.parquet(F\"{DLK_LOCATION}/{cc_policy_path}\")\r\n",
					"display(df)"
				],
				"execution_count": 22
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"ccx_HealthCare_WC_schema = StructType([StructField('ID',IntegerType(),True)\r\n",
					"                                ,StructField('ClaimID',IntegerType(),True)\r\n",
					"                                ,StructField('InjuryTreatedLocation',IntegerType(),True)\r\n",
					"                                ,StructField('HCReceived',IntegerType(),True)\r\n",
					"                                ,StructField('HCReceivedDate',DateType(),True)\r\n",
					"                                ,StructField('updatetime',TimestampType(), True)\r\n",
					"                                ,StructField('audit_batch_ts',TimestampType(), True)])\r\n",
					"ccx_HealthCare_WC_path = \"wsib_raw_sample_data/psaprod.ccx_HealthCare_WC.parquet\"\r\n",
					"ccx_HealthCare_WC_data = [[fake.random_int(min=1,max=1000)\r\n",
					"                    ,fake.random_int(min=1,max=1000)\r\n",
					"                    ,fake.random_int(min=10001,max=10008)\r\n",
					"                    ,fake.random_int(max=1)\r\n",
					"                    ,fake.date_this_month()\r\n",
					"                    ,fake.date_time_this_month()\r\n",
					"                    ,fake.date_time_this_month()] for i in range(1000)]\r\n",
					"\r\n",
					"create_sample_parquet_file(df_schema=ccx_HealthCare_WC_schema, \r\n",
					"                            df_data=ccx_HealthCare_WC_data, \r\n",
					"                            destination_path=ccx_HealthCare_WC_path\r\n",
					"                            )             "
				],
				"execution_count": 23
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"df = spark.read.parquet(F\"{DLK_LOCATION}/{ccx_HealthCare_WC_path}\")\r\n",
					"display(df)"
				],
				"execution_count": 24
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"ccx_LossTimeRTW_WC_schema = StructType([StructField('ID',IntegerType(),True)\r\n",
					"                                ,StructField('ClaimID',IntegerType(),True)\r\n",
					"                                ,StructField('MWAcceptance',IntegerType(),True)\r\n",
					"                                ,StructField('MWDateOfOffer',DateType(),True)\r\n",
					"                                ,StructField('updatetime',TimestampType(), True)\r\n",
					"                                ,StructField('audit_batch_ts',TimestampType(), True)])\r\n",
					"ccx_LossTimeRTW_WC_path = \"wsib_raw_sample_data/psaprod.ccx_LossTimeRTW_WC.parquet\"\r\n",
					"ccx_LossTimeRTW_WC_data = [[fake.random_int(max=1000)\r\n",
					"                    ,fake.random_int(min=1,max=1000)\r\n",
					"                    ,fake.random_int(max=1)\r\n",
					"                    ,fake.date_this_month()\r\n",
					"                    ,fake.date_time_this_month()\r\n",
					"                    ,fake.date_time_this_month()] for i in range(1000)]\r\n",
					"\r\n",
					"create_sample_parquet_file(df_schema=ccx_LossTimeRTW_WC_schema, \r\n",
					"                            df_data=ccx_LossTimeRTW_WC_data, \r\n",
					"                            destination_path=ccx_LossTimeRTW_WC_path\r\n",
					"                            )                "
				],
				"execution_count": 25
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"df = spark.read.parquet(F\"{DLK_LOCATION}/{ccx_LossTimeRTW_WC_path}\")\r\n",
					"display(df)"
				],
				"execution_count": 26
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"cc_bodypart_schema = StructType([StructField('ID',IntegerType(),True)\r\n",
					"                                ,StructField('IncidentID',IntegerType(),True)\r\n",
					"                                ,StructField('PrimaryBodyPart',StringType(),True)\r\n",
					"                                ,StructField('DetailedBodyPart',StringType(),True)\r\n",
					"                                ,StructField('updatetime',TimestampType(), True)\r\n",
					"                                ,StructField('audit_batch_ts',TimestampType(), True)])\r\n",
					"cc_bodypart_path = \"wsib_raw_sample_data/psaprod.cc_bodypart.parquet\"\r\n",
					"cc_bodypart_data = [[fake.random_int(max=1000)\r\n",
					"                    ,fake.random_int(min=1,max=1000)\r\n",
					"                    ,fake.body_part_detailed()\r\n",
					"                    ,fake.body_part_detailed()\r\n",
					"                    ,fake.date_time_this_month()\r\n",
					"                    ,fake.date_time_this_month()] for i in range(1000)]\r\n",
					"\r\n",
					"create_sample_parquet_file(df_schema=cc_bodypart_schema, \r\n",
					"                            df_data=cc_bodypart_data, \r\n",
					"                            destination_path=cc_bodypart_path\r\n",
					"                            )             "
				],
				"execution_count": 27
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"df = spark.read.parquet(F\"{DLK_LOCATION}/{cc_bodypart_path}\")\r\n",
					"display(df)"
				],
				"execution_count": 28
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"cc_exposure_schema = StructType([StructField('ID',IntegerType(),True)\r\n",
					"                                ,StructField('ClaimID',IntegerType(),True)])\r\n",
					"cc_exposure_path = \"wsib_raw_sample_data/psaprod.cc_exposure.parquet\"\r\n",
					"cc_exposure_data = [[fake.random_int(max=1000)\r\n",
					"                    ,fake.random_int(min=1,max=1000)] for i in range(1000)]\r\n",
					"\r\n",
					"create_sample_parquet_file(df_schema=cc_exposure_schema, \r\n",
					"                            df_data=cc_exposure_data, \r\n",
					"                            destination_path=cc_exposure_path\r\n",
					"                            )           "
				],
				"execution_count": 29
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"df = spark.read.parquet(F\"{DLK_LOCATION}/{cc_exposure_path}\")\r\n",
					"display(df)"
				],
				"execution_count": 30
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"ccx_WSIB_Inc2Sequence_schema = StructType([StructField('ID',IntegerType(),True)\r\n",
					"                                ,StructField('BenefitType',IntegerType(),True)\r\n",
					"                                ,StructField('Exposure',IntegerType(),True)\r\n",
					"                                ,StructField('SequenceStatus',IntegerType(),True)\r\n",
					"                                ,StructField('EntitlementPercent',FloatType(),True)\r\n",
					"                                ,StructField('SequenceFromDate',DateType(),True)\r\n",
					"                                ,StructField('SequenceToDate',DateType(),True)\r\n",
					"                                ,StructField('updatetime',TimestampType(), True)\r\n",
					"                                ,StructField('audit_batch_ts',TimestampType(), True)])\r\n",
					"ccx_WSIB_Inc2Sequence_path = \"wsib_raw_sample_data/psaprod.ccx_WSIB_Inc2Sequence.parquet\"\r\n",
					"ccx_WSIB_Inc2Sequence_data = [[fake.random_int(max=1000)\r\n",
					"                    ,fake.random_element(elements=(10001, 10002, 10043, 10044))\r\n",
					"                    ,fake.random_int()\r\n",
					"                    ,10001\r\n",
					"                    ,round(random.uniform(0,1),3)\r\n",
					"                    ,fake.date_this_month()\r\n",
					"                    ,fake.date_this_month()\r\n",
					"                    ,fake.date_time_this_month()\r\n",
					"                    ,fake.date_time_this_month()] for i in range(1000)]\r\n",
					"\r\n",
					"create_sample_parquet_file(df_schema=ccx_WSIB_Inc2Sequence_schema, \r\n",
					"                            df_data=ccx_WSIB_Inc2Sequence_data, \r\n",
					"                            destination_path=ccx_WSIB_Inc2Sequence_path\r\n",
					"                            )                   "
				],
				"execution_count": 31
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"df = spark.read.parquet(F\"{DLK_LOCATION}/{ccx_WSIB_Inc2Sequence_path}\")\r\n",
					"display(df)"
				],
				"execution_count": 32
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"ccx_WSIB_ProjectID_schema = StructType([StructField('ID',IntegerType(),True)\r\n",
					"                                ,StructField('WSIB_ProjectCode',StringType(),True)])\r\n",
					"ccx_WSIB_ProjectID_path= \"wsib_raw_sample_data/psaprod.ccx_WSIB_ProjectID.parquet\"\r\n",
					"ccx_WSIB_ProjectID_data = [[fake.random_int(max=1000)\r\n",
					"                    , 'NCOV2019'] for i in range(1000)]\r\n",
					"\r\n",
					"create_sample_parquet_file(df_schema=ccx_WSIB_ProjectID_schema, \r\n",
					"                            df_data=ccx_WSIB_ProjectID_data, \r\n",
					"                            destination_path=ccx_WSIB_ProjectID_path\r\n",
					"                            )           "
				],
				"execution_count": 33
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"df = spark.read.parquet(F\"{DLK_LOCATION}/{ccx_WSIB_ProjectID_path}\")\r\n",
					"display(df)"
				],
				"execution_count": 34
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# https://learn.microsoft.com/en-us/azure/synapse-analytics/spark/apache-spark-pool-configurations"
				],
				"execution_count": 35
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"WSIB_NTL_dataset_schema = StructType([StructField('Age_grp',IntegerType(),True)\r\n",
					"                                ,StructField('Bodypart_cnt',IntegerType(),True)\r\n",
					"                                ,StructField('COVID19',IntegerType(),True)\r\n",
					"                                ,StructField('CUMSUMRate',FloatType(),True)\r\n",
					"                                ,StructField('DUR',IntegerType(),True)\r\n",
					"                                ,StructField('Gender',IntegerType(),True)\r\n",
					"                                ,StructField('GRP_AccidentCatOptns20',IntegerType(),True)\r\n",
					"                                ,StructField('grp_AccidentIllnessCat',StringType(),True)\r\n",
					"                                ,StructField('grp_Bodypart10',StringType(),True)\r\n",
					"                                ,StructField('GRP_FIRMSIZE',IntegerType(),True)\r\n",
					"                                ,StructField('GRP_NatureOfAccident',StringType(),True)\r\n",
					"                                ,StructField('GRP_NatureOfAccident20',StringType(),True)\r\n",
					"                                ,StructField('GRP_Rate10',StringType(),True)\r\n",
					"                                ,StructField('HCreg_loc',StringType(),True)\r\n",
					"                                ,StructField('Prior_claims',IntegerType(),True)\r\n",
					"                                ,StructField('PriorSimilarCond_WC',IntegerType(),True)\r\n",
					"                                ,StructField('Reg_grp',IntegerType(),True)\r\n",
					"                                ,StructField('RegToDec_grp',IntegerType(),True)\r\n",
					"                                ,StructField('S2',IntegerType(),True)\r\n",
					"                                ])\r\n",
					"WSIB_NTL_dataset_path= \"wsib_raw_sample_data/psaprod.WSIB_NTL_dataset.parquet\"\r\n",
					"WSIB_NTL_dataset_data = [[fake.random_int(min=0,max=6)\r\n",
					"                          ,fake.random_int(min=1,max=5)\r\n",
					"                          ,fake.random_int(min=0,max=1)\r\n",
					"                          ,round(random.uniform(0,1),3)\r\n",
					"                          ,fake.random_int(min=0,max=1)\r\n",
					"                          ,fake.random_int(min=1,max=2)\r\n",
					"                          ,fake.random_int(min=1,max=20)\r\n",
					"                          ,fake.random_element(elements=('4-Other', '1-Gradual','2-OD','3-Psych'))\r\n",
					"                          ,fake.random_int(min=0,max=9)\r\n",
					"                          ,fake.random_int(min=0,max=8)\r\n",
					"                          ,fake.random_int(min=1,max=4)\r\n",
					"                          ,fake.random_int(min=1,max=20)\r\n",
					"                          ,fake.random_int(min=0,max=9)\r\n",
					"                          ,fake.random_element(elements=('Clinic', 'Office','Hosp','Trauma','Other'))\r\n",
					"                          ,fake.random_int(min=0,max=1)\r\n",
					"                          ,fake.random_int(min=0,max=1)\r\n",
					"                          ,fake.random_int(min=0,max=2)\r\n",
					"                          ,fake.random_int(min=0,max=2)\r\n",
					"                          ,fake.random_int(min=0,max=1)\r\n",
					"                           ] for i in range(1000)]\r\n",
					"\r\n",
					"create_sample_parquet_file(df_schema=WSIB_NTL_dataset_schema, \r\n",
					"                            df_data=WSIB_NTL_dataset_data, \r\n",
					"                            destination_path=WSIB_NTL_dataset_path\r\n",
					"                            )     "
				],
				"execution_count": 6
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"df = spark.read.parquet(F\"{DLK_LOCATION}/{WSIB_NTL_dataset_path}\")\r\n",
					"display(df)"
				],
				"execution_count": 7
			}
		]
	}
}